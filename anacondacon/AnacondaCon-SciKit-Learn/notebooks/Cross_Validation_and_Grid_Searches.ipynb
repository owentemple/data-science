{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png'>\n",
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Classification](#Classification)\n",
    "\t* [Logistic regression](#Logistic-regression)\n",
    "\t* [*k*-nearest neighbors](#*k*-nearest-neighbors)\n",
    "* [Cross-validation](#Cross-validation)\n",
    "\t* [Cross-validation in scikit-learn](#Cross-validation-in-scikit-learn)\n",
    "\t* [Stratified K-Fold cross-validation and other strategies](#Stratified-K-Fold-cross-validation-and-other-strategies)\n",
    "\t* [More control over cross-validation](#More-control-over-cross-validation)\n",
    "\t\t* [Leave-One-Out cross-validation](#Leave-One-Out-cross-validation)\n",
    "\t\t* [Shuffle-Split cross-validation](#Shuffle-Split-cross-validation)\n",
    "* [Grid Search](#Grid-Search)\n",
    "\t* [Simple Grid-Search](#Simple-Grid-Search)\n",
    "\t* [The danger of overfitting the parameters and the validation set](#The-danger-of-overfitting-the-parameters-and-the-validation-set)\n",
    "\t* [Grid-search with cross-validation](#Grid-search-with-cross-validation)\n",
    "\t\t* [`sklearn.model_selection.GridSearchCV`](#sklearn.model_selection.GridSearchCV)\n",
    "\t* [Analyzing the result of cross-validation](#Analyzing-the-result-of-cross-validation)\n",
    "\t* [Nested cross-validation](#Nested-cross-validation)\n",
    "* [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.rcParams['image.interpolation'] = \"none\"\n",
    "np.set_printoptions(precision=3)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['legend.numpoints'] = 1\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import src.mglearn as mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification models predict the association of observation to discrete labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'][:471])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.read_csv('data/iris.csv'), hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "<img src='./img/topics/Essential-Concept.png' align='left' style='padding:10px'>\n",
    "<big><big><br>\n",
    "LogisticRegression models predict probabilities for association to discrete labels.\n",
    "<br><br>\n",
    "</big></big>\n",
    "</div>\n",
    "\n",
    "Logistic regression is conceptually similar to linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting a data set into separate sets of data for training and testing (validation) allows evaluation of model fit on data outside the training inputs.\n",
    "\n",
    "The next cells shows a single split using `train_test_split` from [sklearn.model_selection](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predicted the correct class on 87% of the samples in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the individual probabilities with each test observation. The highest probably is returned by `.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logreg.predict_proba(X_test), columns=[iris.target_names]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *k*-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "<img src='./img/topics/Essential-Concept.png' align='left' style='padding:10px'>\n",
    "<big><big><br>\n",
    "KNN predicts new observations only by considering proximity to training set\n",
    "<br><br>\n",
    "</big></big>\n",
    "</div>\n",
    "\n",
    "The more neighbors that are considered the more *general* the model is. Considering only 1 nearest neighbor is likely *overfitting*.\n",
    "\n",
    "The KNN classifier is considered a good exploratory model but may not be heavily used in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering three neighbors in 4-dimensional space leads to 97% accuracy.\n",
    "\n",
    "We got lucky that we didn't run into the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn3.fit(X_train, y_train)\n",
    "knn3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was much more decisive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(knn3.predict_proba(X_test), columns=[iris.target_names]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to our score if:\n",
    "- we retain more or less rows in `train_test_split`?\n",
    "- we call `train_test_split` with a different `random_state`?\n",
    "\n",
    "A good model will have a stable score under each of the above conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "<img src='./img/topics/Essential-Concept.png' align='left' style='padding:10px'>\n",
    "<big><big><br>\n",
    "Cross validation fold: a random single split of training and testing data\n",
    "<br><br>\n",
    "</big></big>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graphic shows the idea of a 5-fold cross validation.  The data are divided randomly into 5 groups (folds) and the model is trained in 5 rounds, where each round trains with 4 data sets then calculates model scores based on the 5th set within each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.model_selection.cross_val_score` below with default arguments is doing 3 cross validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is very stable when choosing 3 folds with 1/3 of the data retained for validation in each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to 5 folds\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize scores\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold cross-validation and other strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratification in sampling can be useful when class membership in the input data are not uniformly distributed.  Some example problems where stratified sampling may be helpful include:\n",
    " * Fraud detection (find a few fraudsters out of many ok customers)\n",
    " * Health sciences (predict presence / absence of uncommon condition)\n",
    " * Reliability engineering (few failing samples and many ok samples)\n",
    " \n",
    "This [lecture from John Hopkins University](http://ocw.jhsph.edu/courses/statmethodsforsamplesurveys/PDFs/Lecture4.pdf) provides an overview of stratified sampling in health sciences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the observations are ordered by species.\n",
    "\n",
    "Luckily, `cross_val_score` didn't grab rows sequentially!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_stratified_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More control over cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `KFold` and `StratifiedKFold` to re-use the folding or control cross validation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retain 1/5 for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(5 , random_state=0)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retain 1/3 for validation, which mean a whole species was ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(3, random_state=0)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 1/9 from each species per fold.\n",
    "\n",
    "For classification the default behavior of `cross_val_score` is to *stratify*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(3, random_state=0)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make *N-1* folds with only one row left for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "print(\"number of cv iterations: \", len(scores))\n",
    "print(\"mean accuracy: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle-Split cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ShuffleSplit](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) guarantees all samples will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search can eliminate hand tuning of model parameters by applying a range of values for each calibrated parameter.  The limitation is that the search space can become large.  Using a grid search approach requires having some model evaluation statistic, such as accuracy or __R<sup>2</sup>__ score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Grid-Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how a custom grid search for model parameters could be done: trying a variety of `gamma` and `C` parameters to a support vector classifier (`SVC`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive grid search implementation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set: %d   size of test set: %d\" % (X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set \n",
    "        score = svm.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "            \n",
    "print(\"best score: \", best_score)\n",
    "print(\"best parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The danger of overfitting the parameters and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "print(\"threefold_split\")\n",
    "mglearn.plots.plot_threefold_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "# split train+validation set into training and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
    "\n",
    "print(\"Size of training set: %d   size of validation set: %d   size of test set: %d\" % (X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set \n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# rebuild a model on the combined training and validation set, and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"best score on validation set: \", best_score)\n",
    "print(\"best parameters: \", best_parameters)\n",
    "print(\"test set score with best parameters: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-search with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This custom grid search example selects by the mean of cross validation scores taken from 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: manual_grid_search_cv\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(svm, X_trainval, y_trainval, cv=5)\n",
    "        # compute mean cross-validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "# rebuild a model on the combined training and validation set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_cross_val_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sklearn.model_selection.GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html) automates the looping-over-models we have done in the cells above.\n",
    "\n",
    "`GridSearchCV` takes a `param_grid` dictionary to specify the parameter search space.  \n",
    "\n",
    "The example below will end up trying 36 models (`len(param_grid['C']) * len(param_grid['gamma'])`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the result of cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GridSearchCV` object after fitting will have the attribute `grid_scores_` that is a sequence of mean validation scores and parameters for each model.  Note the `grid_scores_` interface is in transition as of scikit-learn version 0.17 - 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can easily convert to dataframe\n",
    "import pandas as pd\n",
    "scores = pd.DataFrame(grid_search.cv_results_)\n",
    "scores.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of cross val scores for each item in grid\n",
    "scores = np.array(scores.mean_test_score).reshape(6, 6)\n",
    "\n",
    "# plot the mean cross-validation scores\n",
    "mglearn.tools.heatmap(scores, xlabel='gamma', ylabel='C', xticklabels=param_grid['gamma'],\n",
    "                      yticklabels=param_grid['C'], cmap=\"viridis\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial and error with different parameter grids, trying log vs linear spacing params\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 5))\n",
    "\n",
    "param_grid_linear = {'C': np.linspace(1, 2, 6),\n",
    "                     'gamma':  np.linspace(1, 2, 6)}\n",
    "\n",
    "param_grid_one_log = {'C': np.linspace(1, 2, 6),\n",
    "                     'gamma':  np.logspace(-3, 2, 6)}\n",
    "\n",
    "param_grid_range = {'C': np.logspace(-3, 2, 6),\n",
    "                     'gamma':  np.logspace(-7, -2, 6)}\n",
    "\n",
    "for param_grid, ax in zip([param_grid_linear, param_grid_one_log,\n",
    "                           param_grid_range], axes):\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    scores = pd.DataFrame(grid_search.cv_results_)\n",
    "    scores = np.array(scores.mean_test_score).reshape(6, 6)\n",
    "\n",
    "    # plot the mean cross-validation scores\n",
    "    scores_image = mglearn.tools.heatmap(scores, xlabel='gamma', ylabel='C', xticklabels=param_grid['gamma'],\n",
    "                                         yticklabels=param_grid['C'], cmap=\"viridis\", ax=ax)\n",
    "    \n",
    "plt.colorbar(scores_image, ax=axes.tolist())\n",
    "print(\"gridsearch_failures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen cross validation of each model within a grid of parameters, but we can also nest the `GridSearchCV` itself in an outer cross validation cycle, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(GridSearchCV(SVC(), param_grid, cv=5), iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(X, y, inner_cv, outer_cv, Classifier, parameter_grid):\n",
    "    outer_scores = []\n",
    "    # for each split of the data in the outer cross-validation\n",
    "    # (split method returns indices)\n",
    "    for training_samples, test_samples in outer_cv.split(X, y):\n",
    "        # find best parameter using inner cross-validation:\n",
    "        best_parms = {}\n",
    "        best_score = -np.inf\n",
    "        # iterate over parameters\n",
    "        for parameters in parameter_grid:\n",
    "            # accumulate score over inner splits\n",
    "            cv_scores = []\n",
    "            # iterate over inner cross-validation\n",
    "            for inner_train, inner_test in inner_cv.split(X[training_samples], y[training_samples]):\n",
    "                # build classifier given parameters and training data\n",
    "                clf = Classifier(**parameters)\n",
    "                clf.fit(X[inner_train], y[inner_train])\n",
    "                # evaluate on inner test set\n",
    "                score = clf.score(X[inner_test], y[inner_test])\n",
    "                cv_scores.append(score)\n",
    "            # compute mean score over inner folds\n",
    "            mean_score = np.mean(cv_scores)\n",
    "            if mean_score > best_score:\n",
    "                # if better than so far, remember parameters\n",
    "                best_score = mean_score\n",
    "                best_params = parameters\n",
    "        # build classifier on best parameters using outer training set\n",
    "        clf = Classifier(**best_params)\n",
    "        clf.fit(X[training_samples], y[training_samples])\n",
    "        # evaluate \n",
    "        outer_scores.append(clf.score(X[test_samples], y[test_samples]))\n",
    "    return outer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "nested_cv(iris.data, iris.target, StratifiedKFold(5), StratifiedKFold(5), SVC, ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we reviewed the following topics in preparation for more advanced topics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Train / test split](#Train-/-test-split)\n",
    " * [Cross-validation](#Cross-validation)\n",
    " * [Cross-validation in scikit-learn](#Cross-validation-in-scikit-learn)\n",
    " * [Leave-One-Out cross-validation](#Leave-One-Out-cross-validation)\n",
    " * [Shuffle-Split cross-validation](#Shuffle-Split-cross-validation)\n",
    " * [Grid Search](#Grid-Search)\n",
    " * [Grid-search with cross-validation](#Grid-search-with-cross-validation)\n",
    " * [Analyzing the result of cross-validation](#Analyzing-the-result-of-cross-validation)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='Cross_Validation_and_Grid_Searches_Exercises.ipynb' class='btn btn-primary btn-lg'>Exercises</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
