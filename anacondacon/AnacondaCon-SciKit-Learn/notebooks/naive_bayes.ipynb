{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png'>\n",
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers learn the *statistical characteristics* of the labels represented in your training data.\n",
    "\n",
    "New observations are compared to those *statistical characteristics* to make a prediction.\n",
    "\n",
    "Naive Bayes classifiers assume *independence between pairs of features*.\n",
    "\n",
    "Naive Bayes classifiers may perform better than linear models for:\n",
    "* many training observations\n",
    "* large number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Naive Bayes classifiers](#Naive-Bayes-classifiers)\n",
    "* [Automobile data](#Automobile-data)\n",
    "* [GaussianNB](#GaussianNB)\n",
    "\t* [Prior probabilities](#Prior-probabilities)\n",
    "\t* [Feature Statistics](#Feature-Statistics)\n",
    "\t\t* [counts](#counts)\n",
    "\t\t* [means](#means)\n",
    "\t\t* [standard deviations](#standard-deviations)\n",
    "* [BernouliNB](#BernouliNB)\n",
    "\t* [get_dummies](#get_dummies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automobile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import src.mglearn as mglearn\n",
    "sns.reset_orig()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto = pd.read_csv('data/auto-mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(auto, vars=['hp','mpg'], hue='origin', size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(auto, random_state=0)\n",
    "\n",
    "X_train = train[['hp', 'mpg']]\n",
    "X_test = test[['hp', 'mpg']]\n",
    "\n",
    "y_train = train['origin']\n",
    "y_test = test['origin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/topics/Essential-Concept.png' align='left'>\n",
    "<div class='alert alert-info' align='center'><font size='+2'>\n",
    "GaussianNB assumes:<br/>an independent Gaussian distribution<br/> for each feature per label\n",
    "</font></div>\n",
    "\n",
    "By learning means and variance predictions are made for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we tell that this model is *actually* doing well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss.fit(X_train, y_train)\n",
    "gauss.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB takes into account the *prior probabilities* of each class in the training data when making a prediction.\n",
    "\n",
    "This helps to reduce the bias in our dataset because most of the cars were made in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(gauss.class_prior_, index=gauss.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.reset_orig()\n",
    "ax.scatter(auto['hp'], auto['mpg'], c=auto['origin'].astype('category').cat.codes)\n",
    "gauss.fit(X_train[['hp','mpg']], y_train.astype('category').cat.codes)\n",
    "mglearn.plot_2d_separator.plot_2d_classification(gauss, auto[['hp','mpg']].values, alpha=0.2, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GaussianNB model trains for:\n",
    "* the number of observations for each label\n",
    "* the mean of each feature per label ($\\theta$)\n",
    "* the variance of each feature per label ($\\sigma$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.groupby('origin')[['hp','mpg']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss.theta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.groupby('origin')[['hp','mpg']].var(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss.sigma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernouliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BernouliNB model is designed to work with binary feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/titanic.csv').dropna()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Pandas DataFrames, using get_dummies transforms multi-categorical columns to separate yes/no observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_dummies = pd.get_dummies(titanic[['sex', 'class', 'embarked', 'adult_male', 'alone','survived']])\n",
    "titanic_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic_dummies, random_state=0)\n",
    "\n",
    "features = titanic_dummies.columns.drop('survived')\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "y_train = train['survived']\n",
    "y_test = test['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BernouliNB model then predicts the probabilities by evaluating the fractional frequency of each feature per label (true/false).\n",
    "\n",
    "The BernouliNB model also provides explicit account for features being absent in an observation. This means that a label that was trained where a feature was entirely False will penalize predictions for that label where those observations are true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bern = BernoulliNB()\n",
    "bern.fit(X_train, y_train)\n",
    "bern.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
