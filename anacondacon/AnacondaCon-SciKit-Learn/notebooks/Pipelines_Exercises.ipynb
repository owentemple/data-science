{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png'>\n",
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the iris data set then use scaling and PCA as `Pipeline` preprocessing steps.  Make a  `Pipeline` for each of the classifiers imported in the following cell, fit each `Pipeline`, and calculate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris_data = datasets.load_iris()\n",
    "examples = iris_data.data\n",
    "classes  = iris_data.target\n",
    "print(classes.shape)\n",
    "print(examples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#soln1\" class='btn btn-primary'>Show solution</button>\n",
    "\n",
    "<div id=\"soln1\" class=\"collapse\">\n",
    "\n",
    "Import some classes for pipelines and scaling, and create a collection of classifiers:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# make a list of classifiers \n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LDA(),\n",
    "    QDA()]\n",
    "```\n",
    "\n",
    "Setup some scaffolding to look at the confusion matrixes of various classifiers:\n",
    "\n",
    "```python\n",
    "# we also see other measures of accuracy\n",
    "import numpy as np\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "# Let's take a look at the \"shape\" of the data\n",
    "examples = iris.data\n",
    "classes = iris.target\n",
    "\n",
    "# Create a training and a testing set from this data by choosing indices\n",
    "# (manually, not with higher-level APIs)\n",
    "def test_once(examples, classes, n_neighbors=5, estimator=None):\n",
    "    # Random order of indices\n",
    "    n_examples = len(examples)\n",
    "    shuffled_indices = np.random.permutation(n_examples)\n",
    "\n",
    "    # Pick a trainig/testing split\n",
    "    train_pct = 0.8\n",
    "    train_ct  = int(n_examples * train_pct)\n",
    "\n",
    "    # Select indices for training and testing\n",
    "    train_idx, test_idx = shuffled_indices[:train_ct], shuffled_indices[train_ct:]\n",
    "    model = Pipeline([('standard', StandardScaler()), \n",
    "                       ('pca', PCA()), \n",
    "                       ('clf', estimator)])\n",
    "    model.fit(examples[train_idx], classes[train_idx])\n",
    "    predictions = model.predict(examples[test_idx])\n",
    "    confusion = confusion_matrix(predictions, classes[test_idx])\n",
    "    accuracy = accuracy_score(predictions, classes[test_idx])\n",
    "    return confusion, accuracy\n",
    "```\n",
    "\n",
    "Take a look at the various classifiers by confusion matrix and accuracy:\n",
    "\n",
    "```python\n",
    "pretty_name = lambda classifier: classifier.__class__.__name__\n",
    "# now we can loop over the classifiers\n",
    "accuracies = []\n",
    "for classifier in classifiers:\n",
    "    print('With classifier', pretty_name(classifier))\n",
    "    confusion, accuracy = test_once(examples, classes, estimator=classifier)\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion)\n",
    "    print('Accuracy', accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    print()\n",
    "idx = accuracies.index(np.max(accuracies))\n",
    "best = classifiers[idx]\n",
    "print('Best model', best, 'accuracy', accuracies[idx])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
